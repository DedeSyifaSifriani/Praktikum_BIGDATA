{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf14wXmVXqJt",
        "outputId": "6494ed1c-e9a3-414c-aed5-eb6bd7812c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "BAGIAN 1: INSTALASI & KONFIGURASI\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"BAGIAN 1: INSTALASI & KONFIGURASI\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸ“¦ Instalasi Java, Kafka, dan Spark...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOPh41HXXsdL",
        "outputId": "d08b3419-1e2f-45b7-fada-9fe3dfc37a13"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“¦ Instalasi Java, Kafka, dan Spark...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "ihbX6y0xaSDI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/kafka/3.6.0/kafka_2.12-3.6.0.tgz\n",
        "!tar -xzf kafka_2.12-3.6.0.tgz"
      ],
      "metadata": {
        "id": "wRp9Q1Csazn2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n"
      ],
      "metadata": {
        "id": "Vq1b9_t3bZqc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark kafka-python\n",
        "\n",
        "print(\"âœ“ Instalasi selesai!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-13nBFNIby3B",
        "outputId": "3a8e904e-78f1-41aa-9a0b-3a4801a4f7b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/326.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m266.2/326.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m326.3/326.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ“ Instalasi selesai!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nâš™ï¸  Konfigurasi Environment Variables...\")\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "os.environ[\"KAFKA_HOME\"] = \"/content/kafka_2.12-3.6.0\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "print(\"âœ“ Environment Variables siap!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWjcnsMEb34r",
        "outputId": "b9758400-275a-4ff0-bb6f-580a8c890778"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âš™ï¸  Konfigurasi Environment Variables...\n",
            "âœ“ Environment Variables siap!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸš€ Menjalankan Zookeeper dan Kafka Broker...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ_1R1JYb_AU",
        "outputId": "fc9a2da1-024a-49cb-eb8c-de9151840d5b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸš€ Menjalankan Zookeeper dan Kafka Broker...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup $KAFKA_HOME/bin/zookeeper-server-start.sh $KAFKA_HOME/config/zookeeper.properties > /dev/null 2>&1 &\n",
        "\n",
        "import time\n",
        "print(\"â³ Menunggu Zookeeper start (10 detik)...\")\n",
        "time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgut4HDvcDtF",
        "outputId": "47d8a6da-392b-4460-88b2-04759e2d9426"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Menunggu Zookeeper start (10 detik)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup $KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties > /dev/null 2>&1 &\n",
        "\n",
        "print(\"â³ Menunggu Kafka Broker start (10 detik)...\")\n",
        "time.sleep(10)\n",
        "\n",
        "print(\"âœ“ Server Kafka siap digunakan!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-a36L1AcJtc",
        "outputId": "9e1db993-6c47-4e58-db90-f6b5b41609ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Menunggu Kafka Broker start (10 detik)...\n",
            "âœ“ Server Kafka siap digunakan!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸ“‹ Membuat Topic Kafka...\")\n",
        "\n",
        "!$KAFKA_HOME/bin/kafka-topics.sh --create --topic transaksi-toko --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1\n",
        "\n",
        "print(\"âœ“ Topik 'transaksi-toko' berhasil dibuat.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8d64uwocYQx",
        "outputId": "19b9db7a-6322-4164-9860-8e3581a2cf96"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“‹ Membuat Topic Kafka...\n",
            "Created topic transaksi-toko.\n",
            "âœ“ Topik 'transaksi-toko' berhasil dibuat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BAGIAN 2: KAFKA PRODUCER - DATA GENERATOR\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from kafka import KafkaProducer\n",
        "import json\n",
        "import random\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQW_CW2_cfBa",
        "outputId": "ad6524ac-a87b-4100-d877-c0aac862b575"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "BAGIAN 2: KAFKA PRODUCER - DATA GENERATOR\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BAGIAN 2: KAFKA PRODUCER - DATA GENERATOR\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from kafka import KafkaProducer\n",
        "import json\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "# Fungsi untuk serialisasi data ke format JSON\n",
        "def json_serializer(data):\n",
        "    return json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "# Inisialisasi Producer\n",
        "producer = KafkaProducer(\n",
        "    bootstrap_servers=['localhost:9092'],\n",
        "    value_serializer=json_serializer\n",
        ")\n",
        "\n",
        "# Daftar produk dummy\n",
        "products = [\"Laptop\", \"Mouse\", \"Keyboard\", \"Monitor\", \"HDMI Cable\"]\n",
        "\n",
        "def send_stream_data(topic_name, num_messages=50):\n",
        "    print(f\"\\nðŸ“¤ Mulai mengirim {num_messages} data ke topik: {topic_name}...\")\n",
        "    for i in range(num_messages):\n",
        "        # Membuat data transaksi palsu\n",
        "        data = {\n",
        "            \"transaction_id\": i,\n",
        "            \"product\": random.choice(products),\n",
        "            \"price\": random.randint(100000, 5000000),\n",
        "            \"quantity\": random.randint(1, 5),\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        }\n",
        "\n",
        "        # Kirim ke Kafka\n",
        "        producer.send(topic_name, data)\n",
        "\n",
        "        # Simulasi jeda waktu antar transaksi (0.1 detik)\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    print(\"âœ“ Selesai mengirim data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlkwOQFgc8sj",
        "outputId": "263c8c9d-c391-4517-af8b-91ecaed4b15f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "BAGIAN 2: KAFKA PRODUCER - DATA GENERATOR\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BAGIAN 3: SPARK STRUCTURED STREAMING - CONSUMER\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Langkah 6: Inisialisasi Spark Session\n",
        "print(\"\\nâš¡ Inisialisasi Spark Session...\")\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import from_json, col, sum as _sum, count\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"KafkaSparkStreamingColab\") \\\n",
        "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "print(\"âœ“ Spark Session aktif.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BON14pn-dC2D",
        "outputId": "d9366149-944c-400e-85d7-e3d4f545a01a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "BAGIAN 3: SPARK STRUCTURED STREAMING - CONSUMER\n",
            "======================================================================\n",
            "\n",
            "âš¡ Inisialisasi Spark Session...\n",
            "âœ“ Spark Session aktif.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸ“– Membaca Stream dari Kafka...\")\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "# 1. Definisi Schema\n",
        "schema = StructType([\n",
        "    StructField(\"transaction_id\", IntegerType(), True),\n",
        "    StructField(\"product\", StringType(), True),\n",
        "    StructField(\"price\", IntegerType(), True),\n",
        "    StructField(\"quantity\", IntegerType(), True),\n",
        "    StructField(\"timestamp\", StringType(), True)\n",
        "])\n",
        "\n",
        "# 2. Read Stream dari Kafka\n",
        "df_raw = spark.readStream \\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "    .option(\"subscribe\", \"transaksi-toko\") \\\n",
        "    .option(\"startingOffsets\", \"earliest\") \\\n",
        "    .load()\n",
        "\n",
        "# 3. Transformasi Data (Parsing JSON)\n",
        "df_parsed = df_raw.select(\n",
        "    from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\")\n",
        ").select(\"data.*\")\n",
        "\n",
        "print(\"âœ“ Schema data:\")\n",
        "df_parsed.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsSTdJGydHNE",
        "outputId": "81ce1137-e6b4-486d-a8f7-189a0b660752"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“– Membaca Stream dari Kafka...\n",
            "âœ“ Schema data:\n",
            "root\n",
            " |-- transaction_id: integer (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            " |-- quantity: integer (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸ“Š Melakukan Agregasi Data...\")\n",
        "\n",
        "# Menambah kolom 'revenue' (price * quantity)\n",
        "df_with_revenue = df_parsed.withColumn(\"revenue\", col(\"price\") * col(\"quantity\"))\n",
        "\n",
        "# Agregasi: Group by Product dan Sum Revenue\n",
        "df_analysis = df_with_revenue.groupBy(\"product\") \\\n",
        "    .agg(_sum(\"revenue\").alias(\"total_sales\")) \\\n",
        "    .orderBy(\"total_sales\", ascending=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8df6_ERwdNYQ",
        "outputId": "4068c4c7-d38a-4ac5-8009-88bfaaf70f38"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Melakukan Agregasi Data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ”„ Memulai Stream Processing...\")\n",
        "\n",
        "query = df_analysis.writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"sales_table\") \\\n",
        "    .start()\n",
        "\n",
        "print(\"âœ“ Stream processing berjalan di background...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY53iC5QdRb2",
        "outputId": "4c001465-a903-4e44-c9ef-f58167a64839"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Memulai Stream Processing...\n",
            "âœ“ Stream processing berjalan di background...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BAGIAN 4: EKSEKUSI & MONITORING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Langkah 10: Mengirim Data & Melihat Hasil\n",
        "def run_analysis():\n",
        "    # 1. Kirim 50 data baru ke Kafka\n",
        "    send_stream_data(\"transaksi-toko\", num_messages=50)\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"ðŸ“ˆ HASIL ANALISIS DARI SPARK\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Tunggu sebentar agar Spark memproses data\n",
        "    time.sleep(5)\n",
        "\n",
        "    # 2. Query tabel hasil olahan Spark menggunakan SQL\n",
        "    result = spark.sql(\"SELECT * FROM sales_table\")\n",
        "    result.show()\n",
        "\n",
        "# Jalankan analisis pertama kali\n",
        "run_analysis()\n",
        "\n",
        "print(\"\\nðŸ’¡ Tip: Jalankan fungsi run_analysis() lagi untuk melihat data terus bertambah!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKrJcziHdXP_",
        "outputId": "2bc476ef-6ac1-4901-b7f0-ca80b772818e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "BAGIAN 4: EKSEKUSI & MONITORING\n",
            "======================================================================\n",
            "\n",
            "ðŸ“¤ Mulai mengirim 50 data ke topik: transaksi-toko...\n",
            "âœ“ Selesai mengirim data.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "ðŸ“ˆ HASIL ANALISIS DARI SPARK\n",
            "----------------------------------------------------------------------\n",
            "+-------+-----------+\n",
            "|product|total_sales|\n",
            "+-------+-----------+\n",
            "+-------+-----------+\n",
            "\n",
            "\n",
            "ðŸ’¡ Tip: Jalankan fungsi run_analysis() lagi untuk melihat data terus bertambah!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TUGAS MANDIRI - MODIFIKASI ANALISIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# TUGAS 1: Tambahkan Total Quantity per Produk\n",
        "print(\"\\nðŸ“ TUGAS 1: Analisis dengan Total Sales + Total Quantity\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Stop query sebelumnya\n",
        "query.stop()\n",
        "time.sleep(2)\n",
        "\n",
        "# Agregasi baru dengan Total Sales dan Total Quantity\n",
        "df_analysis_extended = df_with_revenue.groupBy(\"product\") \\\n",
        "    .agg(\n",
        "        _sum(\"revenue\").alias(\"total_sales\"),\n",
        "        _sum(\"quantity\").alias(\"total_quantity\")\n",
        "    ) \\\n",
        "    .orderBy(\"total_sales\", ascending=False)\n",
        "\n",
        "# Start query baru\n",
        "query_extended = df_analysis_extended.writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"sales_extended_table\") \\\n",
        "    .start()\n",
        "\n",
        "print(\"âœ“ Query dengan Total Quantity dimulai...\")\n",
        "\n",
        "# Kirim data dan tampilkan hasil\n",
        "send_stream_data(\"transaksi-toko\", num_messages=50)\n",
        "time.sleep(5)\n",
        "\n",
        "print(\"\\nðŸ“Š Hasil Analisis (Total Sales + Total Quantity):\")\n",
        "result_extended = spark.sql(\"SELECT * FROM sales_extended_table\")\n",
        "result_extended.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPtWthibdl9M",
        "outputId": "9ca0a981-d58e-485b-d23b-3c3d893459fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TUGAS MANDIRI - MODIFIKASI ANALISIS\n",
            "======================================================================\n",
            "\n",
            "ðŸ“ TUGAS 1: Analisis dengan Total Sales + Total Quantity\n",
            "----------------------------------------------------------------------\n",
            "âœ“ Query dengan Total Quantity dimulai...\n",
            "\n",
            "ðŸ“¤ Mulai mengirim 50 data ke topik: transaksi-toko...\n",
            "âœ“ Selesai mengirim data.\n",
            "\n",
            "ðŸ“Š Hasil Analisis (Total Sales + Total Quantity):\n",
            "+-------+-----------+--------------+\n",
            "|product|total_sales|total_quantity|\n",
            "+-------+-----------+--------------+\n",
            "+-------+-----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TUGAS 2: Filter Transaksi dengan Price > 1.000.000\n",
        "print(\"\\nðŸ“ TUGAS 2: Filter Transaksi Price > 1.000.000\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Stop query sebelumnya\n",
        "query_extended.stop()\n",
        "time.sleep(2)\n",
        "\n",
        "# Tambahkan filter untuk price > 1000000\n",
        "df_filtered = df_with_revenue.filter(col(\"price\") > 1000000)\n",
        "\n",
        "df_analysis_filtered = df_filtered.groupBy(\"product\") \\\n",
        "    .agg(\n",
        "        _sum(\"revenue\").alias(\"total_sales\"),\n",
        "        _sum(\"quantity\").alias(\"total_quantity\"),\n",
        "        count(\"*\").alias(\"transaction_count\")\n",
        "    ) \\\n",
        "    .orderBy(\"total_sales\", ascending=False)\n",
        "\n",
        "# Start query dengan filter\n",
        "query_filtered = df_analysis_filtered.writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"sales_filtered_table\") \\\n",
        "    .start()\n",
        "\n",
        "print(\"âœ“ Query dengan filter Price > 1.000.000 dimulai...\")\n",
        "\n",
        "# Kirim data dan tampilkan hasil\n",
        "send_stream_data(\"transaksi-toko\", num_messages=50)\n",
        "time.sleep(5)\n",
        "\n",
        "print(\"\\nðŸ“Š Hasil Analisis (Hanya Transaksi > 1 Juta):\")\n",
        "result_filtered = spark.sql(\"SELECT * FROM sales_filtered_table\")\n",
        "result_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSnehTm7doFY",
        "outputId": "4f4458d2-2912-4a97-d9e2-9c8b0628af67"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“ TUGAS 2: Filter Transaksi Price > 1.000.000\n",
            "----------------------------------------------------------------------\n",
            "âœ“ Query dengan filter Price > 1.000.000 dimulai...\n",
            "\n",
            "ðŸ“¤ Mulai mengirim 50 data ke topik: transaksi-toko...\n",
            "âœ“ Selesai mengirim data.\n",
            "\n",
            "ðŸ“Š Hasil Analisis (Hanya Transaksi > 1 Juta):\n",
            "+-------+-----------+--------------+-----------------+\n",
            "|product|total_sales|total_quantity|transaction_count|\n",
            "+-------+-----------+--------------+-----------------+\n",
            "+-------+-----------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TUGAS 3 (OPSIONAL): Append Mode\n",
        "print(\"\\nðŸ“ TUGAS 3 (OPSIONAL): Append Mode - Raw Transactions\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Stop query sebelumnya\n",
        "query_filtered.stop()\n",
        "time.sleep(2)\n",
        "\n",
        "# Append mode: tampilkan raw transactions tanpa agregasi\n",
        "query_append = df_with_revenue.writeStream \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"transactions_raw\") \\\n",
        "    .start()\n",
        "\n",
        "print(\"âœ“ Query Append Mode dimulai...\")\n",
        "\n",
        "# Kirim beberapa data\n",
        "send_stream_data(\"transaksi-toko\", num_messages=20)\n",
        "time.sleep(5)\n",
        "\n",
        "print(\"\\nðŸ“Š Raw Transactions (Append Mode):\")\n",
        "result_raw = spark.sql(\"SELECT transaction_id, product, price, quantity, revenue FROM transactions_raw LIMIT 20\")\n",
        "result_raw.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5Ekfg-0duWc",
        "outputId": "c5f51bc9-80e9-44e1-86f4-67c9f004c05c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“ TUGAS 3 (OPSIONAL): Append Mode - Raw Transactions\n",
            "----------------------------------------------------------------------\n",
            "âœ“ Query Append Mode dimulai...\n",
            "\n",
            "ðŸ“¤ Mulai mengirim 20 data ke topik: transaksi-toko...\n",
            "âœ“ Selesai mengirim data.\n",
            "\n",
            "ðŸ“Š Raw Transactions (Append Mode):\n",
            "+--------------+----------+-------+--------+--------+\n",
            "|transaction_id|   product|  price|quantity| revenue|\n",
            "+--------------+----------+-------+--------+--------+\n",
            "|             0|   Monitor|4678968|       3|14036904|\n",
            "|             1|  Keyboard|1573421|       1| 1573421|\n",
            "|             2|HDMI Cable|2649274|       5|13246370|\n",
            "|             3|  Keyboard|2881302|       4|11525208|\n",
            "|             4|   Monitor|2973933|       4|11895732|\n",
            "|             5|     Mouse| 511946|       5| 2559730|\n",
            "|             6|     Mouse|2710600|       2| 5421200|\n",
            "|             7|HDMI Cable|1016730|       5| 5083650|\n",
            "|             8|    Laptop| 471640|       1|  471640|\n",
            "|             9|    Laptop|4173357|       4|16693428|\n",
            "|            10|   Monitor|4397626|       4|17590504|\n",
            "|            11|    Laptop|2439887|       4| 9759548|\n",
            "|            12|  Keyboard|3852250|       4|15409000|\n",
            "|            13|   Monitor| 119548|       5|  597740|\n",
            "|            14|HDMI Cable|1310282|       4| 5241128|\n",
            "|            15|  Keyboard|2325457|       5|11627285|\n",
            "|            16|  Keyboard|3476549|       5|17382745|\n",
            "|            17|HDMI Cable|2555005|       3| 7665015|\n",
            "|            18|     Mouse|1901626|       1| 1901626|\n",
            "|            19|  Keyboard|4308561|       2| 8617122|\n",
            "+--------------+----------+-------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MEMBERSIHKAN RESOURCES\")\n",
        "print(\"=\" * 70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMWjMlhMd4qr",
        "outputId": "c677887a-f19f-4a55-c8b4-356dd01728a0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "MEMBERSIHKAN RESOURCES\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 11: Menghentikan Program\n",
        "query_append.stop()\n",
        "print(\"âœ“ Streaming dihentikan.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"âœ… PRAKTIKUM SELESAI!\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nðŸ’¡ Ringkasan yang telah dikerjakan:\")\n",
        "print(\"   âœ“ Setup Kafka & Spark di Google Colab\")\n",
        "print(\"   âœ“ Membuat Producer untuk mengirim data dummy\")\n",
        "print(\"   âœ“ Membuat Consumer dengan Spark Structured Streaming\")\n",
        "print(\"   âœ“ TUGAS 1: Analisis Total Sales + Total Quantity\")\n",
        "print(\"   âœ“ TUGAS 2: Filter transaksi Price > 1.000.000\")\n",
        "print(\"   âœ“ TUGAS 3: Implementasi Append Mode\")\n",
        "\n",
        "# Uncomment jika ingin menghentikan Spark Session\n",
        "# spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwJ6lM6Sd-Jm",
        "outputId": "dafbd310-4f60-4cd0-84ea-078b1256e97b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Streaming dihentikan.\n",
            "\n",
            "======================================================================\n",
            "âœ… PRAKTIKUM SELESAI!\n",
            "======================================================================\n",
            "\n",
            "ðŸ’¡ Ringkasan yang telah dikerjakan:\n",
            "   âœ“ Setup Kafka & Spark di Google Colab\n",
            "   âœ“ Membuat Producer untuk mengirim data dummy\n",
            "   âœ“ Membuat Consumer dengan Spark Structured Streaming\n",
            "   âœ“ TUGAS 1: Analisis Total Sales + Total Quantity\n",
            "   âœ“ TUGAS 2: Filter transaksi Price > 1.000.000\n",
            "   âœ“ TUGAS 3: Implementasi Append Mode\n"
          ]
        }
      ]
    }
  ]
}